<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Qiucheng Wu</title>
  
  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Qiucheng Wu</name>
              </p>
              <p>I am a final-year Ph.D. student in Computer Science at the University of California, Santa Barbara, under the supervision of <a href="https://code-terminator.github.io/index.html">Prof. Shiyu Chang</a>. I received my bachelor’s and master’s degrees from the University of Michigan, College of Engineering, and a second bachelor’s degree at Shanghai Jiao Tong University.</p>
              <p>
                My research focuses on generative models at the intersection of vision and language. Specifically, I am interested in:
              </p>
              <ul style="margin:8px 0 8px 20px;">
                <li>The imbalanced capability of multimodal large language models (MLLMs) in understanding visual and textual information, and methods to enhance their performance on visual tasks.</li>
                <li>Text control in visual generative models (e.g., diffusion models, GANs) for images and videos.</li>
              </ul>
              <p>
                Some of my projects and publications are shown below.
              </p>
              <p style="text-align:center">
                Email: <a href="mailto:qiucheng@ucsb.edu">qiucheng@ucsb.edu</a>&nbsp;/&nbsp;
                <a href="data/QiuchengWu_Resume.pdf">CV</a>
              </p>
            </td>
            <td style="padding:2.5%;width:30%;max-width:30%">
              <img style="width:80%;max-width:80%" alt="profile photo" src="images/Qiucheng.png" class="hoverZoomLink">
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research Projects</heading>
              <p>
                * indicates authors with equal contributions.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="lssr_stop()" onmouseover="lssr_start()">
            <td style="padding:20px;width:35%;vertical-align:middle">
              <div class="one">
                <img src='images/VSP.png' width="240">
              </div>
            </td>
            <td style="padding:20px;width:65%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2407.01863">
                <papertitle>VSP: Diagnosing the Dual Challenges of Perception and Reasoning in Spatial Planning Tasks for MLLMs</papertitle>
              </a>
              <br>
              <strong>Qiucheng Wu</strong>, Handong Zhao, Michael Saxon, Trung Bui, William Yang Wang, Yang Zhang, and Shiyu Chang.
              <br>
              <em>ICCV</em>, 2025 <a href="https://github.com/UCSB-NLP-Chang/Visual-Spatial-Planning">[Code]</a>
              <br>
              <p></p>
              <p>
                To diagnose the imbalance between visual and textual understanding in MLLMs, we introduce VSP, focusing on evaluating their spatial planning ability and further analyzing weaknesses through fine-grained perception and reasoning tasks.
              </p>
            </td>
          </tr>
          <tr onmouseout="lssr_stop()" onmouseover="lssr_start()">
            <td style="padding:20px;width:35%;vertical-align:middle">
              <div class="one">
                <img src='images/SpatialTemporal.png' width="240">
              </div>
            </td>
            <td style="padding:20px;width:65%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Harnessing_the_Spatial-Temporal_Attention_of_Diffusion_Models_for_High-Fidelity_Text-to-Image_ICCV_2023_paper.pdf">
                <papertitle>Harnessing the Spatial-Temporal Attention of Diffusion Models for High-Fidelity Text-to-Image Synthesis</papertitle>
              </a>
              <br>
              <strong>Qiucheng Wu</strong>*, Yujian Liu*, Handong Zhao, Trung Bui, Zhe Lin, Yang Zhang, Shiyu Chang
              <br>
              <em>ICCV</em>, 2023 <a href="https://github.com/UCSB-NLP-Chang/Diffusion-SpaceTime-Attn">[Code]</a>
              <br>
              <p></p>
              <p>
                We propose a new text-to-image algorithm with explicit control over cross-attention in diffusion models from spatial and temporal views. This alleviates inconsistencies between images and text and helps to fix errors like missing objects, mismatched attributes, and mislocated objects. 
              </p>
            </td>
          </tr>
          <tr onmouseout="lssr_stop()" onmouseover="lssr_start()">
            <td style="padding:20px;width:35%;vertical-align:middle">
              <div class="one">
                <img src='images/diffusiondisentangle.png' width="240">
              </div>
            </td>
            <td style="padding:20px;width:65%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_Uncovering_the_Disentanglement_Capability_in_Text-to-Image_Diffusion_Models_CVPR_2023_paper.pdf">
                <papertitle>Uncovering the Disentanglement Capability in Text-to-Image Diffusion Models</papertitle>
              </a>
              <br>
              <strong>Qiucheng Wu</strong>, Yujian Liu, Handong Zhao, Ajinkya Kale, Trung Bui, Tong Yu, Zhe Lin, Yang Zhang, Shiyu Chang
              <br>
              <em>CVPR</em>, 2023 <a href="https://github.com/UCSB-NLP-Chang/DiffusionDisentanglement">[Code]</a> <a href="https://wuqiuche.github.io/DiffusionDisentanglement-project-page/">[Demo]</a>
              <br>
              <p></p>
              <p>
                Based on a fixed stable diffusion model, we disentangle target attributes from a single training image. The learned parameters can then be applied to unseen images and achieve the same edits. This finding leads to a lightweight image editing framework with only 50 learnable parameters.
              </p>
            </td>
          </tr>
          <tr onmouseout="lssr_stop()" onmouseover="lssr_start()">
            <td style="padding:20px;width:35%;vertical-align:middle">
              <div class="one">
                <img src='images/adadeblur.png' width="240">
              </div>
            </td>
            <td style="padding:20px;width:65%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10254493">
                <papertitle>Broad Spectrum Image Deblurring via An Adaptive Super-Network</papertitle>
              </a>
              <br>
              <strong>Qiucheng Wu*</strong>, Yifan Jiang*, Junru Wu*, Victor Kulikov, Vidit Goel, Nikita Orlov, Humphrey Shi, Zhangyang Wang, Shiyu Chang 
              <br>
              <em>IEEE Transactions on Image Processing (TIP)</em>, 2023<a href="https://github.com/wuqiuche/Ada-Deblur"> [Code]</a>
              <br>
              <p></p>
              <p>
                We propose Ada-Deblur, a super-network that can be applied to a "broad spectrum" of various blur levels with no retraining on novel blurs.
              </p>
            </td>
          </tr>
          <tr onmouseout="lssr_stop()" onmouseover="lssr_start()">
            <td style="padding:20px;width:35%;vertical-align:middle">
              <div class="one">
                <img src='images/grasping.png' width="240">
              </div>
            </td>
            <td style="padding:20px;width:65%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2204.12696.pdf">
                <papertitle>Grasping the Arrow of Time from the Singularity: Decoding Micromotion in Low-dimensional Latent Spaces from StyleGAN</papertitle>
              </a>
              <br>
              <strong>Qiucheng Wu*</strong>, Yifan Jiang*, Junru Wu*, Kai Wang, Gong Zhang, Humphrey Shi, Zhangyang Wang, Shiyu Chang
              <br>
              <em>CPAL</em>, 2024 <a href="https://github.com/wuqiuche/micromotion-styleGAN">[Code]</a> <a href="https://wuqiuche.github.io/micromotion-project-page/">[Demo]</a>
              <br>
              <p></p>
              <p>
                
              </p>
            </td>
          </tr>
          <tr onmouseout="lssr_stop()" onmouseover="lssr_start()">
            <td style="padding:20px;width:35%;vertical-align:middle">
              <div class="one">
                <img src='images/TemporalFiltering.png' width="240">
              </div>
            </td>
            <td style="padding:20px;width:65%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2212.08698.pdf">
                <papertitle>Temporal Frame Filtering with Near-Pixel Compute for Autonomous Driving</papertitle>
              </a>
              <br>
              Wantong Li, <strong>Qiucheng Wu</strong>, Janak Sharda, Shiyu Chang, Shimeng Yu
              <br>
              <em>IEEE 4th International Conference on Artificial Intelligence Circuits and Systems (AICAS)</em>, 2022
              <br>
              <p></p>
              <p>

              </p>
            </td>
          </tr>
          <tr onmouseout="lssr_stop()" onmouseover="lssr_start()">
            <td style="padding:20px;width:35%;vertical-align:middle">
              <div class="one">
                <img src='images/tridesign.png' width="240">
              </div>
            </td>
            <td style="padding:20px;width:65%;vertical-align:middle">
              <a href="https://dl.acm.org/doi/pdf/10.1145/3566097.3567864">
                <papertitle>Data-Model-Circuit Tri-Design for Ultra-Light Video Intelligence on Edge Devices</papertitle>
              </a>
              <br>
              Yimeng Zhang*, Akshay Karkal Kamath*, <strong>Qiucheng Wu</strong>*, Zhiwen Fan*, Wuyang Chen, Zhangyang Wang, Shiyu Chang, Sijia Liu, Cong Hao
              <br>
              <em>Proceedings of the 28th Asia and South Pacific Design Automation Conference</em>, 2023
              <br>
              <p></p>
              <p>

              </p>
            </td>
          </tr>
          <tr onmouseout="lssr_stop()" onmouseover="lssr_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/ActionTranslator.png' width="240">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ojs.aaai.org/index.php/AAAI/article/view/20635">
                <papertitle>Learning Action Translator for Meta Reinforcement Learning on Sparse Rewards Tasks</papertitle>
              </a>
              <br>
              Yijie Guo, <strong>Qiucheng Wu</strong>, Honglak Lee
              <br>
              <em>AAAI</em>, 2022
              <br>
              <p></p>
              <p>
                Meta reinforcement learning requires substantial amounts of data. To improve the sample efficiency and performance of metal-RL algorithms on sparse-reward tasks, we introduce a novel objective function to learn an action translator among training tasks.
              </p>
            </td>
          </tr>
          <tr onmouseout="lssr_stop()" onmouseover="lssr_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/SifterText.png' width="240">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle"> 
              <a href="https://link.springer.com/article/10.1007/s10916-022-01880-6">
                <papertitle>DataSifterText: Partially Synthetic Text Generation for Sensitive Clinical Notes</papertitle>
              </a>
              <br>
              Nina Zhou, <strong>Qiucheng Wu</strong>, Zewen Wu, Simeone Marino, and Ivo Dinov
              <br>
              <em>Journal of Medical Systems</em>, 2022 
              <br>
              <p></p>
              <p>
                We propose DataSifter-Text to protect privacy of sensitive textual dataset. The DataSifter-Text obfuscates identifiable information in the dataset. It effectively balances between privacy and utility.
              </p>
            </td>
          </tr> 
          <tr onmouseout="lssr_stop()" onmouseover="lssr_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/CBDA.png' width="240">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0228520">
                <papertitle>Compressive Big Data Analytics: An ensemble meta-algorithm for high-dimensional multisource datasets</papertitle>
              </a>
              <br>
              Simeone Marino, Yi Zhao, Nina Zhou, Yiwang Zhou, Arthur W. Toga, Lu Zhao, Yingsi Jian, Yichen Yang, Yehu Chen, <strong>Qiucheng Wu</strong>, Jessica Wild, Brandon Cummings, Ivo D. Dinov
              <br>
              <em>PLOS One</em>, 2020 
              <br>
              <p></p>
              <p>
                We apply the compressive big data analytics (CBDA) to analyze salient features and key biomarkers of a high-dimensional clinical dataset.
              </p>
              <p></p>
              <p>
                Most Likely Health Impact in 4th Annual Symposium Poster Competition in Michigan Institute for Data Science, University of Michigan.
              </p>
            </td>
          </tr>
          <tr onmouseout="lssr_stop()" onmouseover="lssr_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/Sifter.png' width="260">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.tandfonline.com/doi/full/10.1080/00949655.2018.1545228">
                <papertitle>DataSifter: Statistical Obfuscation of Electronic Health Records and Other Sensitive Datasets</papertitle>
              </a>
              <br>
              Simeone Marino, Nina Zhou, Yi Zhao, Lu Wang, <strong>Qiucheng Wu</strong>, Ivo D. Dinov
              <br>
              <em>Journal of Statistical Computation and Simulation</em>, 2019
              <br>
              <p></p>
              <p>
                We propose DataSifter to obfuscate sensitive clinical datasets while preserving utility for downstream tasks.
              </p>
              <p></p>
              <p>
                Most Interesting Methodological Advances in 4th Annual Symposium Poster Competition in Michigan Institute for Data Science, University of Michigan.
              </p>
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Education</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="lssr_stop()" onmouseover="lssr_start()">
            <td style="padding:20px;width:100%;vertical-align:middle">
              <strong>UC Santa Barbara</strong>
              <br>
              Final-year Ph.D. student, Sep 2021 - Current
            </td>
          </tr>
          <tr onmouseout="lssr_stop()" onmouseover="lssr_start()">
            <td style="padding:20px;width:100%;vertical-align:middle">
              <strong>University of Michigan</strong><br>
              M.S., Computer Science and Engineering, Sep 2019 – May 2021<br>
              B.S., Computer Science, Sep 2017 – May 2019<br>
              GPA: 3.94/4.00<br>
              <strong>Focus Areas</strong>
              <li>Natural Language Processing</li>
              <li>Deep Learning for Vision</li>
              <li>Data Mining</li>
            </td>
          </tr>
          <tr onmouseout="lssr_stop()" onmouseover="lssr_start()">
            <td style="padding:20px;width:100%;vertical-align:middle">
              <strong>Shanghai Jiao Tong University</strong><br>
              B.S., Electrical and Computer Engineering, Sep 2015 – Aug 2019<br>
              GPA: 3.67/4.00<br>
              Capstone Gold Prize (2019)
            </td>
          </tr> 
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Work Experience</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="lssr_stop()" onmouseover="lssr_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/adobe.png' width="100">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <strong>Adobe</strong><br>
              Research Intern<br>
              Summer 2023, Summer 2024, Summer 2025
              <ul style="margin:8px 0 6px 18px;">
                <li>Trained efficient multimodal LLM agents for Photoshop/Lightroom workflows.</li>
                <li>Developed text-based controllable image/video generation with diffusion models.</li>
              </ul>
              <p style="margin:0;">
                <em>Outcomes:</em> <a href="https://arxiv.org/pdf/2407.01863">ICCV 2025</a>, <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Harnessing_the_Spatial-Temporal_Attention_of_Diffusion_Models_for_High-Fidelity_Text-to-Image_ICCV_2023_paper.pdf">ICCV 2023</a>, <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_Uncovering_the_Disentanglement_Capability_in_Text-to-Image_Diffusion_Models_CVPR_2023_paper.pdf">CVPR 2023</a>
              </p>
            </td>
          </tr>
          <tr onmouseout="lssr_stop()" onmouseover="lssr_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/picsart.jpg' width="100">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <strong>Picsart</strong><br>
              Research Intern<br>
              Summer 2022
              <ul style="margin:8px 0 6px 18px;">
                <li>Explored controllable image generation with GANs for creative editing tools.</li>
                <li>Image restoration through adaptive deblurring methods.</li>
              </ul>
              <p style="margin:0;">
                <em>Outcomes:</em> <a href="https://arxiv.org/pdf/2204.12696.pdf">CPAL 2024</a>, <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10254493">TIP 2023</a>
              </p>
            </td>
          </tr> 
          <tr onmouseout="lssr_stop()" onmouseover="lssr_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/Fitly.png' width="100">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <strong>Fitly</strong><br>
              Machine Learning Engineer Intern<br>
              2019 – 2020
              <ul style="margin:8px 0 6px 18px;">
                <li>Developed personalized ML models to improve few-shot food classification accuracy in a nutrition app.</li>
              </ul>
            </td>
          </tr> 
        </tbody></table>

        <!-- Teaching Experience (compact) -->
        <table style="width:100%;border:0;border-spacing:0;border-collapse:separate;margin:0 auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Teaching Experience</heading>
              <p style="margin:8px 0 0 0;">
                • CS165B: Machine Learning (TA, Fall 2021, Winter 2024, UCSB) <br>
                • EECS 492: Intro to Artificial Intelligence (TA, Fall 2020, Winter 2021, UMich) <br>
                • Vv156: Applied Honors Calculus (TA, Fall 2016, UM-SJTU Joint Institute)
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Others</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="lssr_stop()" onmouseover="lssr_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/IntelAkraino.png' width="160">
              </div>
              <script type="text/javascript">
                function lssr_start() {
                  document.getElementById('lssr_image').style.opacity = "1";
                }

                function lssr_stop() {
                  document.getElementById('lssr_image').style.opacity = "0";
                }
                lssr_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Intel Akraino: Edge Cloud Game Architecture</papertitle>
              <br>
              <strong>Capstone Gold Prize</strong>
              <br>
              UM-SJTU Joint Institute, Shanghai Jiao Tong University,
              August 2019
              <p></p>
              <p>
                In this capstone project, we designed a framework to boost web communications between terminal devices and servers by introducing edge servers. We use Kubernetes to organize edge servers as different containers. The edge servers are responsible for computing and sending information to terminal devices, leading to more efficient performance.
              </p>
            </td>
          </tr> 
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
               <br>
               <p style="text-align:right;font-size:small;">
                This website is built using the source code from Jon Barron's <a href="https://jonbarron.info/">public academic website</a>. 
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
